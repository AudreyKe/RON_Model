{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600408301552",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 汽油辛烷值优化建模\n",
    "\n",
    "以下解题过程中：\n",
    "+ 参数定义\n",
    "    - 《附件一：325个样本数据.xlsx》以符号 $\\displaystyle{\\mathcal{X}}_{s}$ 表示\n",
    "    - 《附件三：285号和313号样本原始数据.xlsx》以符号 $\\displaystyle{\\mathcal{X}}_{r}$ 表示"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "source": [
    "sample_data = \"../附件一：325个样本数据.xlsx\"\n",
    "raw_data = \"../附件三：285号和313号样本原始数据.xlsx\"\n",
    "adjust_data = \"../附件四：354个操作变量信息.xlsx\""
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raws = pd.read_excel(io=raw_data, sheet_name=\"操作变量\", header=[0, 1], skiprows=[0])\n",
    "samples = pd.read_excel(io=sample_data, header=[0, 1], skiprows=[0])\n",
    "\n",
    "# 查看 原始数据情况\n",
    "# raws \n",
    "# 查看 样本数据情况\n",
    "# samples"
   ]
  },
  {
   "source": [
    "### 问题一：\n",
    "\n",
    "数据处理：请参考近4年的工业数据(见附件一“325个数据样本数据.xlsx”)的预处理结果，依“样本确定方法”（附件二）对285号和313号数据样本进行预处理（原始数据见附件三“285号和313号样本原始数据.xlsx”）并将处理后的数据分别加入到附件一中相应的样本号中，供下面研究使用。\n",
    "\n",
    "即 数据预处理 ====> 补全数据&修正数据\n",
    "\n",
    "解题思路：\n",
    "\n",
    "+ 认真阅读《附件二：样本确定方法.docx》\n",
    "+ 补全数据：\n",
    "    - 即需要先确认 样本数据集 $\\displaystyle{\\mathcal{X}}_{s}$ 中 285号 $x_{s}^{(285)}$ 和 313号 $x_{s}^{(313)}$ 存在属性值缺失的属性集合 $\\displaystyle{\\mathcal{D}}_{loss}$\n",
    "    - 将缺失的属性集合 $\\displaystyle{\\mathcal{D}}_{loss}$ 中的缺失的属性值从 原始数据集 $\\displaystyle{\\mathcal{X}}_{r}$ 中以求取均值 mean($\\displaystyle{\\mathcal{V}_{r}}$) 的方式确定\n",
    "+ 修正数据：\n",
    "    - 即需要先确认 原始数据集 $\\displaystyle{\\mathcal{X}}_{r}$ 中 285号 $x_{s}^{(285)}$ 和 313号 $x_{s}^{(313)}$ 样本中各属性的属性值缺失情况，对于缺失情况较大的属性则不对 样本数据集 $\\displaystyle{\\mathcal{X}}_{s}$ 中的 属性值 $\\displaystyle{\\mathcal{D}}$ 进行修正\n",
    "    - 将 285号 $x_{s}^{(285)}$ 和 313号 $x_{s}^{(313)}$ 样本中需要修正的属性采用 变异系数 std($\\displaystyle{\\mathcal{V}_{r}}$)/mean($\\displaystyle{\\mathcal{V}_{r}}$) 来判断数据的离散程度，然后依据 正态分布假设检验 $norm(d \\sim (mean(\\displaystyle{\\mathcal{V}_{r}})，std(\\displaystyle{\\mathcal{V}_{r}})))$，然后使用 依达拉原则 剔除一些不在范围内的样本，然后进行求取均值的操作\n",
    "\n",
    "代码逻辑：\n",
    "\n",
    "+ 补全数据：\n",
    "    - 首先从 样本数据集 $\\displaystyle{\\mathcal{X}}_{s}$ 中确定样本 285号 $x_{s}^{(285)}$ 和 313号 $x_{s}^{(313)}$ 缺失的属性 $\\displaystyle{\\mathcal{D}}_{loss}$\n",
    "    - 然后对缺失的属性 $d_{loss} \\in \\displaystyle{\\mathcal{D}}_{loss}$ 对应到 原始数据集 $\\displaystyle{\\mathcal{X}}_{r}$ 中，逐一对每个缺失的属性值进行判别\n",
    "    - 这里使用 $\\frac{\\displaystyle{\\mathbb{I}}(v_{loss}^{(i)} \\ne 0|d_{loss}^{(i)}  \\in \\displaystyle{\\mathcal{D}}_{loss})}{\\displaystyle{\\mathbb{I}}(v_{loss}^{(i)} |d_{loss}^{(i)} \\in \\displaystyle{\\mathcal{D}}_{loss})}$ 对当前 缺失的属性 $d_{loss}$ 在 原始数据集 $\\displaystyle{\\mathcal{X}}_{r}$ 中数据采集的状况进行评估\n",
    "        + 当比值 $ \\ge \\frac{3}{4} $ 时，对当前 缺失的属性的值 $\\displaystyle{\\mathcal{V}_{d_{loss}}}$ 进行求均值 mean($\\displaystyle{\\mathcal{V}_{d_{loss}}}$) 处理；\n",
    "        + 当比值 $ < \\frac{3}{4} $ 时，对当前 缺失的属性 $d_{loss}$ 进行直接忽略处理；\n",
    "\n",
    "+ 修正数据：\n",
    "    + 对样本 $x_{sample}^{(i)}$ 进行 缺失的属性 $d_{loss}$ 求均值之前需进行异常值处理\n",
    "        - 根据拉依达准则（3$\\sigma$准则）去除异常值，得到 缺失的属性 $d_{loss}$ 对应的过滤后的 原始属性值集合 $\\displaystyle{\\mathcal{V}}_{filter}^{d_{loss}}$\n",
    "        - 将处理后的 原始属性值集合 $\\displaystyle{\\mathcal{V}}_{filter}^{d_{loss}}$ 中的属性值进行求 均值 $\\displaystyle{\\mathcal{V}}_{filter_{mean}}^{d_{loss}}$ 操作加入到 $\\displaystyle{\\mathcal{X}}_{s}$ 中对应的 样本数据 $x_{s}^{(i)}$ 对应的 缺失的属性 $d_{loss}$ 中"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No.285 样本\n",
    "sample_285 = samples.iloc[284]\n",
    "sample_285 = sample_285.drop(index=sample_285.index[[x for x in range(1, 16)]], axis=1)\n",
    "# No.313 样本\n",
    "sample_313 = samples.iloc[312]\n",
    "sample_313 = sample_313.drop(index=sample_285.index[[x for x in range(1, 16)]], axis=1)\n",
    "\n",
    "# 查看 No.285 数据情况\n",
    "# sample_285\n",
    "# 查看 No.313 数据情况\n",
    "# sample_313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_dummy_colmuns(sample):\n",
    "    dummy_columns = []\n",
    "    for (code_name, i18n_name) in sample.keys():\n",
    "        if not sample[(code_name, i18n_name)]:\n",
    "            # 查看 样本属性值 为 0 的列名\n",
    "            # print(f\"{'='*10}{i18n_name}{'='*10}\")\n",
    "            # print(f\"{code_name}: => {sample[(code_name, i18n_name)]}\")\n",
    "            # print(f\"{'='*35}\")\n",
    "            dummy_columns.append(code_name)\n",
    "    return dummy_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_285_dummy_columns = find_dummy_colmuns(sample_285)\n",
    "sample_313_dummy_columns = find_dummy_colmuns(sample_313)\n",
    "\n",
    "# 查看 No.285 属性值为空的情况\n",
    "print(f\"No.285 属性值为空的列: {sample_285_dummy_columns}\")\n",
    "# 查看 No.313 属性值为空的情况\n",
    "print(f\"No.313 属性值为空的列: {sample_313_dummy_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 拆分原始数据中285号样本的数据\n",
    "print(\"拆分出来的285号样本的原始数据\")\n",
    "raw_285 = raws.iloc[:40]\n",
    "raw_285[sample_285_dummy_columns].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 拆分原始数据中313号样本的数据\n",
    "print(\"拆分出来的313号样本的原始数据\")\n",
    "raw_313 = raws.iloc[41:]\n",
    "raw_313[sample_313_dummy_columns].head(n=5)"
   ]
  },
  {
   "source": [
    "至此对于原始数据中的 补全数据操作 完成，可惜的是从结果看起来上面所罗列的原始数据并没有对285号和313号样本的缺失的属性值有所帮助\n",
    "\n",
    "接下来将以原始数据集展开对样本数据集中285号和313号样本的属性值进行修正操作，值得庆幸的是，这一步可以省略上面已经验证的无法补全的一些缺失属性"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 统计 No.285 样本 中属性中属性值存在空值的属性\n",
    "raw_285 = raw_285.drop(raw_285[sample_285_dummy_columns], axis=1)\n",
    "raw_285_nonzeroratio = raw_285.astype(bool).sum(axis=0) / 40\n",
    "raw_285_dummy_columns = []\n",
    "for (code_name, i18n_name) in raw_285_nonzeroratio.keys():\n",
    "    if raw_285_nonzeroratio[(code_name, i18n_name)] != 1.0:\n",
    "        raw_285_dummy_columns.append(code_name)\n",
    "print(raw_285_dummy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 依据 拉依达准则 对 No.285 样本进行属性值数据修正\n",
    "raw_285_filter = raw_285.replace(0, np.NaN)\n",
    "raw_285_filter_describe = raw_285_filter.describe()\n",
    "temp_ratio = raw_285_filter_describe.loc['std'] / raw_285_filter_describe.loc['mean']\n",
    "for (code_name, i18n_name) in temp_ratio.keys():\n",
    "    if temp_ratio[(code_name, i18n_name)] > 0.3:\n",
    "        print(f\"{'='*10} code_name: {code_name} {'='*10}\")\n",
    "        print(f\"样本数据 参照 => {sample_313[(code_name, i18n_name)]}\")\n",
    "        print(f\"原始数据 均值 => {raw_285_filter_describe.loc['mean', (code_name, i18n_name)]}\")\n",
    "        print(f\"原始数据 方差 => {raw_285_filter_describe.loc['std', (code_name, i18n_name)]}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        print(f\"变异系数 => {temp_ratio[(code_name, i18n_name)]}\")\n",
    "        norm_test = stats.kstest(raw_285_filter[(code_name, i18n_name)], 'norm', (raw_285_filter_describe.loc['mean', (code_name, i18n_name)], raw_285_filter_describe.loc['std', (code_name, i18n_name)]))\n",
    "        \n",
    "        print(f\"正态检验 => {norm_test.pvalue}\")\n",
    "        if norm_test.pvalue > 0.05:\n",
    "            print(f\"正态分布检验成功，依据3σ原则进行修正\")\n",
    "            temp_data = raw_285_filter[(code_name, i18n_name)][np.abs(raw_285_filter[(code_name, i18n_name)] - raw_285_filter_describe.loc['mean', (code_name, i18n_name)]) <= 3 * raw_285_filter_describe.loc['std', (code_name, i18n_name)]]\n",
    "            print(f\"修正数据 均值 => {temp_data.mean()}\")\n",
    "            sample_285[(code_name, i18n_name)] = temp_data.mean()\n",
    "            print(f\"样本数据 修正 => {sample_285[(code_name, i18n_name)]}\")\n",
    "        else:\n",
    "            print(f\"正态分布检验失败，不对样本数据进行修正\")\n",
    "        print(f\"{'='*40}\")\n",
    "    else:\n",
    "        sample_285[(code_name, i18n_name)] = raw_285_filter_describe.loc['mean', (code_name, i18n_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 统计 No.313 样本 中属性中属性值存在空值的属性\n",
    "raw_313 = raw_313.drop(raw_313[sample_313_dummy_columns], axis=1)\n",
    "raw_313_nonzeroratio = raw_313.astype(bool).sum(axis=0) / 40\n",
    "raw_313_dummy_columns = []\n",
    "for (code_name, i18n_name) in raw_313_nonzeroratio.keys():\n",
    "    if raw_313_nonzeroratio[(code_name, i18n_name)] != 1.0:\n",
    "        raw_313_dummy_columns.append(code_name)\n",
    "print(raw_313_dummy_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化呈现 No.313 样本 中属性中属性值存在空值的属性的分布\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "msno.matrix(raw_313[raw_313_dummy_columns].replace(0, np.nan), labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 No.313 样本中 存在属性值缺失的 属性进行统计学描述\n",
    "dummy_raw_313 = raw_313[raw_313_dummy_columns].replace(0, np.NaN)\n",
    "dummy_raw_313.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 依据 拉依达准则 对 No.313 样本进行属性值数据修正\n",
    "raw_313_filter = raw_313.drop(raw_313[['S-ZORB.FT_2431.DACA']], axis=1).replace(0, np.NaN)\n",
    "raw_313_filter_describe = raw_313_filter.describe()\n",
    "temp_ratio = raw_313_filter_describe.loc['std'] / raw_313_filter_describe.loc['mean']\n",
    "for (code_name, i18n_name) in temp_ratio.keys():\n",
    "    if temp_ratio[(code_name, i18n_name)] > 0.3:\n",
    "        print(f\"{'='*10} code_name: {code_name} {'='*10}\")\n",
    "        print(f\"样本数据 参照 => {sample_313[(code_name, i18n_name)]}\")\n",
    "        print(f\"原始数据 均值 => {raw_313_filter_describe.loc['mean', (code_name, i18n_name)]}\")\n",
    "        print(f\"原始数据 方差 => {raw_313_filter_describe.loc['std', (code_name, i18n_name)]}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        print(f\"变异系数 => {temp_ratio[(code_name, i18n_name)]}\")\n",
    "        norm_test = stats.kstest(raw_313_filter[(code_name, i18n_name)], 'norm', (raw_313_filter_describe.loc['mean', (code_name, i18n_name)], raw_313_filter_describe.loc['std', (code_name, i18n_name)]))\n",
    "        \n",
    "        print(f\"正态检验 => {norm_test.pvalue}\")\n",
    "        if norm_test.pvalue > 0.05:\n",
    "            print(f\"正态分布检验成功，依据3σ原则进行修正\")\n",
    "            temp_data = raw_313_filter[(code_name, i18n_name)][np.abs(raw_313_filter[(code_name, i18n_name)] - raw_313_filter_describe.loc['mean', (code_name, i18n_name)]) <= 3 * raw_313_filter_describe.loc['std', (code_name, i18n_name)]]\n",
    "            print(f\"修正数据 均值 => {temp_data.mean()}\")\n",
    "            sample_313[(code_name, i18n_name)] = temp_data.mean()\n",
    "            print(f\"样本数据 修正 => {sample_313[(code_name, i18n_name)]}\")\n",
    "        else:\n",
    "            print(f\"正态分布检验失败，不对样本数据进行修正\")\n",
    "        print(f\"{'='*40}\")\n",
    "    else:\n",
    "        sample_313[(code_name, i18n_name)] = raw_313_filter_describe.loc['mean', (code_name, i18n_name)]"
   ]
  },
  {
   "source": [
    "### 问题二：\n",
    "\n",
    "寻找建模主要变量：建立降低辛烷值损失模型涉及包括7个原料性质、2个待生吸附剂性质、2个再生吸附剂性质、2个产品性质等变量以及另外354个操作变量（共计367个变量），工程技术应用中经常使用先降维后建模的方法，这有利于忽略次要因素，发现并分析影响模型的主要变量与因素。因此，请你们根据提供的325个样本数据（见附件一），通过降维的方法从367个操作变量中筛选出建模主要变量，使之尽可能具有代表性、独立性（为了工程应用方便，建议降维后的主要变量在30个以下），并请详细说明建模主要变量的筛选过程及其合理性。（提示：请考虑将原料的辛烷值作为建模变量之一）。\n",
    "\n",
    "即 特征工程 -- 特征选择&数据降维\n",
    "\n",
    "解题思路：\n",
    "+ 特征选择\n",
    "    - 数据值是否缺失过多：如果一个特征的样本数据缺失较多，则无法统计其对目标的影响，将该变量删除\n",
    "        - 具体方法：分别统计操作变量的缺失值数量，然后计算其在数据中的比例，超过一定比例的特征可以删除\n",
    "    - 特征是否发散：如果一个特征不发散，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用\n",
    "        - 具体方法：分别计算操作变量的方差，按方差的大小（需要结合《附件四：354个操作变量信息.xlsx》中的变量阈值进行归一化处理）进行排序（从大到小排），末尾删除一定数量\n",
    "    - 特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择，反之则相反\n",
    "        - 具体方法：利用决策树算法，即采用方差的方法对特征值进行判别，每次选取一个特征值时会\n",
    "\n",
    "> 在特征选择步骤中如果处理后存在未删除的缺失数据，需要考虑对缺失数据的补充，可以考虑对该数据的分布进行概率分布建模（例如：高斯分布）来确定其值，需要，即在进行数据降维操作之前，需要对数据完整性进行保证\n",
    "\n",
    "+ 数据降维 (需要注意：“它们的操作变量（控制变量）之间具有高度非线性和相互强耦联的关系”题干中已经明确说明了)\n",
    "    - 特征之间的相关性：因为操作变量之间是非线性关系，因此无法使用常规的线性降维方式，需要采用流形学习和核化方式对操作变量进行降维\n",
    "        - 具体方法：利用t-SNE对操作变量进行降维\n",
    "        "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将 No.285 样本和 No.313 样本的修正数据替换到 样本数据 中\n",
    "samples.iloc[284] = sample_285\n",
    "samples.iloc[312] = sample_313\n",
    "\n",
    "samples.iloc[:5, 16:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_nonzeroratio = samples.astype(bool).sum(axis=0) / 325\n",
    "samples_dummy_columns = []\n",
    "for (code_name, i18n_name) in samples_nonzeroratio.keys():\n",
    "    if samples_nonzeroratio[(code_name, i18n_name)] != 1.0:\n",
    "        print(f\"code_name: {code_name} => nonzero_ratio: {samples_nonzeroratio[(code_name, i18n_name)]}\")\n",
    "        samples_dummy_columns.append(code_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化呈现 样本数据 中属性中属性值存在空值的属性的分布\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "msno.matrix(samples[samples_dummy_columns].replace(0, np.nan), labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对 缺失值较多属性值 的属性进行丢弃 对 缺失值较少属性值 的属性进行插值\n",
    "samples_delete_columns = []\n",
    "samples_insert_columns = []\n",
    "for (code_name, i18n_name) in samples_nonzeroratio.keys():\n",
    "    if samples_nonzeroratio[(code_name, i18n_name)] < 0.8:\n",
    "        # print(f\"code_name: {code_name} => nonzero_ratio: {samples_nonzeroratio[(code_name, i18n_name)]}\")\n",
    "        samples_delete_columns.append((code_name, i18n_name))\n",
    "    elif 0.8 <= samples_nonzeroratio[(code_name, i18n_name)] < 1:\n",
    "        samples_insert_columns.append((code_name, i18n_name))\n",
    "# print(samples_insert_columns)\n",
    "samples = samples.drop(columns=samples_delete_columns, axis=1)\n",
    "samples = samples.replace(0, np.nan).interpolate()\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化呈现 样本数据 中属性中属性值插值的情况\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "msno.matrix(samples[samples_insert_columns].replace(0, np.nan), labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 提取 操作属性特征 同时 计算 每个属性与目标值的 相关系数，在 阈值 以下的属性将被丢弃\n",
    "samples_features = samples.drop(samples.columns[[x for x in range(0, 2)]], axis=1)\n",
    "samples_features = samples_features.drop(samples_features.columns[[x for x in range(7, 14)]], axis=1)\n",
    "# 相关系数的阈值\n",
    "dist_standard1 = 0.2  # 需要调整的参数\n",
    "samples_delete_columns = []\n",
    "for (code_name, i18n_name) in samples_features.keys():\n",
    "    RON_feature_corr = samples[('产品性质', '辛烷值RON')].corr(samples_features[(code_name, i18n_name)])\n",
    "    corr_dist = np.linalg.norm(RON_feature_corr - 0)\n",
    "    if corr_dist < dist_standard1:\n",
    "        samples_delete_columns.append((code_name, i18n_name))\n",
    "samples_features = samples_features.drop(samples_delete_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = samples[('产品性质', '辛烷值RON')].to_numpy()\n",
    "X = samples_features.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold,datasets\n",
    "# 使用 T-SNE 进行数据降维\n",
    "# X是特征，不包含target; X_tsne 是已经降维之后的特征\n",
    "# 指定降维后的维数\n",
    "re_dimension = 40  # 需要调整的参数\n",
    "tsne = manifold.TSNE(n_components=re_dimension, init='pca', random_state=501, method=\"exact\")\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(f\"原始样本数据维度 {X.shape[-1]}. t-SNE降维后的数据维度 {X_tsne.shape[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 根据 新特征属性 与 辛烷值含量RON 的相关系数，筛选 相关系数 大于设定阈值的 新特征属性 作为构建函数目标属性\n",
    "# 相关系数的阈值\n",
    "dist_standard2 = 0.1  # 需要调整的参数\n",
    "tSNE_samples_features = pd.DataFrame(data=X_tsne, columns=[f'feature_{x + 1}' for x in range(re_dimension)])\n",
    "for _ in tSNE_samples_features.keys():\n",
    "    RON_feature_corr = samples[('产品性质', '辛烷值RON')].corr(tSNE_samples_features[_])\n",
    "    corr_dist = np.linalg.norm(RON_feature_corr - 0)\n",
    "    print(f\"{'='*10} 特征名称: {_} {'='*10}\")\n",
    "    print(f\"与 辛烷值RON含量 的相关系数: {corr_dist}\")\n",
    "    if corr_dist > dist_standard2:\n",
    "        print(f\"作为评估产品中 辛烷值RON含量 的 特征属性\")\n",
    "    else:\n",
    "        print(f\"不作为评估产品中 辛烷值RON含量 的 特征属性\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}